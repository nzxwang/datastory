{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\"raw\")\n",
    "raws = [raw_path for raw_path in raw_dir.ls() if \".tif\" in raw_path.as_posix()]\n",
    "images = sorted([raw_path for raw_path in raws if \"_image\" in raw_path.name])\n",
    "labels = sorted([raw_path for raw_path in raws if \"_label\" in raw_path.name])\n",
    "processed_dir = Path(\"processed\")\n",
    "\n",
    "l=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(23)\n",
    "cutoff=1\n",
    "empty = 0\n",
    "R_popu = 0\n",
    "popu = 0\n",
    "\n",
    "for image_path,label_path in zip(images,labels):\n",
    "    image = cv.imread(image_path.as_posix(), cv.COLOR_BGR2GRAY)\n",
    "    label = cv.imread(label_path.as_posix(), cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    if image.shape != label.shape:\n",
    "        raise ValueError(image_path.as_posix() + label_path.as_posix())\n",
    "    i_max = image.shape[0]//l\n",
    "    j_max = image.shape[1]//l\n",
    "\n",
    "# If the cells were labelled as 255, or something else mistakenly, instead of 1.\n",
    "    label[label!=0]=1\n",
    "\n",
    "    for i in range(i_max):\n",
    "        for j in range(j_max):\n",
    "            cropped_image = image[l*i:l*(i+1), l*j:l*(j+1)]\n",
    "            cropped_label = label[l*i:l*(i+1), l*j:l*(j+1)]\n",
    "            \n",
    "            if (\"_R_\" in image_path.as_posix() and (cropped_label!=0).any()):\n",
    "                R_popu+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + label_path.suffix)\n",
    "            elif \"_R_\" in image_path.as_posix():\n",
    "                continue\n",
    "            elif (cropped_label!=0).any():\n",
    "                popu+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + label_path.suffix)\n",
    "            elif random.random() >= cutoff:\n",
    "                empty+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + \"_empty\" + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + \"_empty\" + label_path.suffix)\n",
    "            else:\n",
    "                continue\n",
    "            cv.imwrite(cropped_image_path.as_posix(), cropped_image)\n",
    "            cv.imwrite(cropped_label_path.as_posix(), cropped_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_popu)\n",
    "print(popu)\n",
    "print(empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 16\n",
    "#bs=16 and l=224 will use ~7300MiB for resnet34  before unfreezing\n",
    "#bs=4 and l=224 use ~12145MiB for resnet50 before unfreezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(\n",
    "    do_flip = True,\n",
    "    flip_vert = True,\n",
    "    max_zoom = 1, #consider\n",
    "    max_rotate = 0,\n",
    "    max_lighting = None,\n",
    "    max_warp = None,\n",
    "    p_affine = 0.75,\n",
    "    p_lighting = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_from_image = lambda path: re.sub(r'_image_', '_label_', path.as_posix())\n",
    "codes = [\"NOT-CELL\", \"CELL\"]\n",
    "def filter_empties(fname, cutoff=0.95):\n",
    "    if \"empty\" in Path(fname).name:\n",
    "        # Return the next random floating point number in the range [0.0, 1.0).\n",
    "        return (random.random() > cutoff)\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "src = (\n",
    "    SegmentationItemList.from_folder(processed_dir)\n",
    "    .filter_by_func(lambda fname:'image' in Path(fname).name)\n",
    "#     .filter_by_func(filter_empties)\n",
    "    .split_by_rand_pct(valid_pct=0.20, seed=2)\n",
    "    .label_from_func(get_label_from_image, classes=codes)\n",
    ")\n",
    "data = (\n",
    "    src.transform(transforms, tfm_y=True)\n",
    "    .databunch(bs=bs)\n",
    "    .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(data, models.resnet34, metrics=partial(dice, iou=True))\n",
    "# learn.loss_func = CrossEntropyFlat(axis=1, weight = torch.Tensor([1,1]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2.5e-3\n",
    "learn.fit_one_cycle(30, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(\"../../models\")\n",
    "learn.save(models_path/\"2019-07-24_RESNET34_IOU0.66_stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(models_path/\"2019-07-24_RESNET34_IOU0.66_stage1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/400,lr/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(12, lrs, pct_start=0.8)\n",
    "# learn.fit_one_cycle(12, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(models_path/\"2019-07-24_RESNET34_IOU0.69_stage2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file = \"../models/2019-07-24_RESNET34_IOU0.69_stage2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.data.valid_ds.__len__()) #list of N\n",
    "print(learn.data.valid_ds[0]) #tuple of input image and segment\n",
    "print(learn.data.valid_ds[0][1])\n",
    "# print(learn.data.valid_ds.__len__())\n",
    "# type(learn.data.valid_ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = learn.get_preds(with_loss=True)\n",
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds)) # tuple of list of probs and targets\n",
    "print(preds[0].shape) #predictions\n",
    "print(preds[0][0].shape) #probabilities for each label\n",
    "print(learn.data.classes) #what is each label\n",
    "print(preds[0][0][0].shape) #probabilities for label 0\n",
    "# for i in range(0,N):\n",
    "#     print(torch.max(preds[0][i][1]))\n",
    "\n",
    "# Image(preds[1][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn.data.valid_ds.__len__() == preds[1].shape[0]:\n",
    "    N = learn.data.valid_ds.__len__()\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "xs = [learn.data.valid_ds[i][0] for i in range(N)]\n",
    "ys = [learn.data.valid_ds[i][1] for i in range(N)]\n",
    "p0s = [Image(preds[0][i][0]) for i in range(N)]\n",
    "p1s = [Image(preds[0][i][1]) for i in range(N)]\n",
    "argmax = [Image(preds[0][i].argmax(dim=0)) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 3\n",
    "nrow = N//ncol + 1\n",
    "fig=plt.figure(figsize=(12, nrow*5))\n",
    "for i in range(1,N):\n",
    "    fig.add_subplot(nrow, ncol, i)\n",
    "#     plt.imshow(xs[i-1].px.permute(1, 2, 0), cmap = \"Oranges\", alpha=0.5)\n",
    "    plt.imshow(argmax[i-1].px, cmap = \"Blues\", alpha=0.7)\n",
    "#     plt.imshow(p1s[i-1].px, cmap = \"Blues\", alpha=0.7)\n",
    "    plt.imshow(ys[i-1].px[0], cmap = \"Oranges\", alpha=0.5)\n",
    "# plt.savefig('/hpf/largeprojects/MICe/nwang/TissueVision/2019-05-31_Mallar_NeuralNet/figures/2019-06-12_mallar-results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wow resnet34 learns the same thing as resnet 50... I wish I did this earlier\n",
    "!jupyter nbconvert arc-venus-train.ipynb --to html --output nbs/2019-07-24_RESNET34_IOU0.69_stage2.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
