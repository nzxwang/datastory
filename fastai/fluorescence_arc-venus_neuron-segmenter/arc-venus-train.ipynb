{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re, os\n",
    "import random\n",
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = Path(\"raw\")\n",
    "    \n",
    "raws = [raw_path for raw_path in raw_dir.ls() if \".tif\" in raw_path.as_posix()]\n",
    "images = sorted([raw_path for raw_path in raws if \"_image\" in raw_path.name])\n",
    "labels = sorted([raw_path for raw_path in raws if \"_label\" in raw_path.name])\n",
    "\n",
    "processed_dir = Path(\"processed\")\n",
    "for f in processed_dir.ls(): os.remove(f)\n",
    "    \n",
    "l=224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "random.seed(23)\n",
    "cutoff=1\n",
    "empty = 0\n",
    "R_popu = 0 #labelled by nick\n",
    "dense_popu = 0 #has dense cells\n",
    "orig_popu = 0 #labelled by Mallar\n",
    "\n",
    "for image_path,label_path in tqdm(zip(images,labels)):\n",
    "    image = cv.imread(image_path.as_posix(), cv.COLOR_BGR2GRAY)\n",
    "    label = cv.imread(label_path.as_posix(), cv.COLOR_BGR2GRAY)\n",
    "\n",
    "    if image.shape != label.shape:\n",
    "        raise ValueError(image_path.as_posix() + label_path.as_posix())\n",
    "    i_max = image.shape[0]//l\n",
    "    j_max = image.shape[1]//l\n",
    "\n",
    "# If the cells were labelled as 255, or something else mistakenly, instead of 1.\n",
    "    label[label!=0]=1\n",
    "\n",
    "    for i in range(i_max):\n",
    "        for j in range(j_max):\n",
    "            cropped_image = image[l*i:l*(i+1), l*j:l*(j+1)]\n",
    "            cropped_label = label[l*i:l*(i+1), l*j:l*(j+1)]\n",
    "            \n",
    "            if \"441.1_\" in image_path.as_posix():\n",
    "                dense_popu+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + label_path.suffix)\n",
    "            elif (\"_R_\" in image_path.as_posix() and (cropped_label!=0).any()):\n",
    "                R_popu+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + label_path.suffix)\n",
    "            elif \"_R_\" in image_path.as_posix():\n",
    "                continue\n",
    "            elif (cropped_label!=0).any():\n",
    "                orig_popu+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + label_path.suffix)\n",
    "            elif random.random() >= cutoff:\n",
    "                empty+=1\n",
    "                cropped_image_path = processed_dir/(image_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + \"_empty\" + image_path.suffix)\n",
    "                cropped_label_path = processed_dir/(label_path.stem + \"_i\" + str(i) + \"_j\" + str(j) + \"_empty\" + label_path.suffix)\n",
    "            else:\n",
    "                continue\n",
    "            cv.imwrite(cropped_image_path.as_posix(), cropped_image)\n",
    "            cv.imwrite(cropped_label_path.as_posix(), cropped_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(R_popu)\n",
    "print(dense_popu)\n",
    "print(orig_popu)\n",
    "print(empty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = get_transforms(\n",
    "    do_flip = True,\n",
    "    flip_vert = True,\n",
    "    max_zoom = 1, #consider\n",
    "    max_rotate = 0,\n",
    "    max_lighting = None,\n",
    "    max_warp = None,\n",
    "    p_affine = 0.75,\n",
    "    p_lighting = 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_label_from_image = lambda path: re.sub(r'_image_', '_label_', path.as_posix())\n",
    "codes = [\"NOT-CELL\", \"CELL\"]\n",
    "\n",
    "bs = 8\n",
    "#without hypercolumns\n",
    "#bs=16 and l=224 will use ~7300MiB for resnet34  before unfreezing\n",
    "#bs=4 and l=224 use ~12145MiB for resnet50 before unfreezing\n",
    "\n",
    "test_dir = Path(\"test\")\n",
    "\n",
    "src = (\n",
    "    SegmentationItemList.from_folder(processed_dir)\n",
    "    .filter_by_func(lambda fname:'image' in Path(fname).name)\n",
    "    .split_by_rand_pct(valid_pct=0.10, seed=2)\n",
    "    .label_from_func(get_label_from_image, classes=codes)\n",
    "    .add_test([path for path in test_dir.ls() if \".tif\" in path.as_posix()],\n",
    "              label=None)\n",
    ")\n",
    "data = (\n",
    "    src.transform(transforms, tfm_y=True)\n",
    "    .databunch(bs=bs)\n",
    "    .normalize(imagenet_stats)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/iafoss/hypercolumns-pneumothorax-fastai-0-831-lb\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "from fastai.vision.learner import create_head, cnn_config, num_features_model, create_head\n",
    "from fastai.callbacks.hooks import model_sizes, hook_outputs, dummy_eval, Hook, _hook_inner\n",
    "from fastai.vision.models.unet import _get_sfs_idxs, UnetBlock\n",
    "\n",
    "class Hcolumns(nn.Module):\n",
    "    def __init__(self, hooks:Collection[Hook], nc:Collection[int]=None):\n",
    "        super(Hcolumns,self).__init__()\n",
    "        self.hooks = hooks\n",
    "        self.n = len(self.hooks)\n",
    "        self.factorization = None \n",
    "        if nc is not None:\n",
    "            self.factorization = nn.ModuleList()\n",
    "            for i in range(self.n):\n",
    "                self.factorization.append(nn.Sequential(\n",
    "                    conv2d(nc[i],nc[-1],3,padding=1,bias=True),\n",
    "                    conv2d(nc[-1],nc[-1],3,padding=1,bias=True)))\n",
    "                #self.factorization.append(conv2d(nc[i],nc[-1],3,padding=1,bias=True))\n",
    "        \n",
    "    def forward(self, x:Tensor):\n",
    "        n = len(self.hooks)\n",
    "        out = [F.interpolate(self.hooks[i].stored if self.factorization is None\n",
    "            else self.factorization[i](self.hooks[i].stored), scale_factor=2**(self.n-i),\n",
    "            mode='bilinear',align_corners=False) for i in range(self.n)] + [x]\n",
    "        return torch.cat(out, dim=1)\n",
    "\n",
    "class DynamicUnet_Hcolumns(SequentialEx):\n",
    "    \"Create a U-Net from a given architecture.\"\n",
    "    def __init__(self, encoder:nn.Module, n_classes:int, blur:bool=False, blur_final=True, \n",
    "                 self_attention:bool=False,\n",
    "                 y_range:Optional[Tuple[float,float]]=None,\n",
    "                 last_cross:bool=True, bottle:bool=False, **kwargs):\n",
    "        imsize = (256,256)\n",
    "        sfs_szs = model_sizes(encoder, size=imsize)\n",
    "        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n",
    "        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n",
    "        x = dummy_eval(encoder, imsize).detach()\n",
    "\n",
    "        ni = sfs_szs[-1][1]\n",
    "        middle_conv = nn.Sequential(conv_layer(ni, ni*2, **kwargs),\n",
    "                                    conv_layer(ni*2, ni, **kwargs)).eval()\n",
    "        x = middle_conv(x)\n",
    "        layers = [encoder, batchnorm_2d(ni), nn.ReLU(), middle_conv]\n",
    "\n",
    "        self.hc_hooks = [Hook(layers[-1], _hook_inner, detach=False)]\n",
    "        hc_c = [x.shape[1]]\n",
    "        \n",
    "        for i,idx in enumerate(sfs_idxs):\n",
    "            not_final = i!=len(sfs_idxs)-1\n",
    "            up_in_c, x_in_c = int(x.shape[1]), int(sfs_szs[idx][1])\n",
    "            do_blur = blur and (not_final or blur_final)\n",
    "            sa = self_attention and (i==len(sfs_idxs)-3)\n",
    "            unet_block = UnetBlock(up_in_c, x_in_c, self.sfs[i], final_div=not_final, \n",
    "                blur=blur, self_attention=sa, **kwargs).eval()\n",
    "            layers.append(unet_block)\n",
    "            x = unet_block(x)\n",
    "            self.hc_hooks.append(Hook(layers[-1], _hook_inner, detach=False))\n",
    "            hc_c.append(x.shape[1])\n",
    "\n",
    "        ni = x.shape[1]\n",
    "        if imsize != sfs_szs[0][-2:]: layers.append(PixelShuffle_ICNR(ni, **kwargs))\n",
    "        if last_cross:\n",
    "            layers.append(MergeLayer(dense=True))\n",
    "            ni += in_channels(encoder)\n",
    "            layers.append(res_block(ni, bottle=bottle, **kwargs))\n",
    "        hc_c.append(ni)\n",
    "        layers.append(Hcolumns(self.hc_hooks, hc_c))\n",
    "        layers += [conv_layer(ni*len(hc_c), n_classes, ks=1, use_activ=False, **kwargs)]\n",
    "        if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "        super().__init__(*layers)\n",
    "\n",
    "    def __del__(self):\n",
    "        if hasattr(self, \"sfs\"): self.sfs.remove()\n",
    "            \n",
    "def unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,\n",
    "        norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, \n",
    "        blur:bool=False, self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, \n",
    "        last_cross:bool=True, bottle:bool=False, cut=None, \n",
    "        hypercolumns=True, **learn_kwargs:Any)->Learner:\n",
    "    \"Build Unet learner from `data` and `arch`.\"\n",
    "    meta = cnn_config(arch)\n",
    "    body = create_body(arch, pretrained, cut)\n",
    "    M = DynamicUnet_Hcolumns if hypercolumns else DynamicUnet\n",
    "    model = to_device(M(body, n_classes=data.c, blur=blur, blur_final=blur_final,\n",
    "        self_attention=self_attention, y_range=y_range, norm_type=norm_type, \n",
    "        last_cross=last_cross, bottle=bottle), data.device)\n",
    "    learn = Learner(data, model, **learn_kwargs)\n",
    "    learn.split(ifnone(split_on, meta['split']))\n",
    "    if pretrained: learn.freeze()\n",
    "    apply_init(model[2], nn.init.kaiming_normal_)\n",
    "    return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = unet_learner(\n",
    "    data,\n",
    "    models.resnet34,\n",
    "    metrics=partial(dice, iou=True),\n",
    "    model_dir='..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(learn)\n",
    "learn.recorder.plot(suggestion=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "learn.fit_one_cycle(15, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"stage1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load(\"stage1\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = slice(lr/800,lr/8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(12, lrs, pct_start=0.8)\n",
    "# learn.fit_one_cycle(12, lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"stage2\") #in processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(file = \"../models/2019-08-21_RESNET34-hcolumns_arcvenus_clusters.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(learn.data.valid_ds.__len__()) #list of N\n",
    "print(learn.data.valid_ds[0]) #tuple of input image and segment\n",
    "print(learn.data.valid_ds[0][1])\n",
    "# print(learn.data.valid_ds.__len__())\n",
    "# type(learn.data.valid_ds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds = learn.get_preds(with_loss=True)\n",
    "preds = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(preds)) # tuple of list of probs and targets\n",
    "print(preds[0].shape) #predictions\n",
    "print(preds[0][0].shape) #probabilities for each label\n",
    "print(learn.data.classes) #what is each label\n",
    "print(preds[0][0][0].shape) #probabilities for label 0\n",
    "# for i in range(0,N):\n",
    "#     print(torch.max(preds[0][i][1]))\n",
    "\n",
    "# Image(preds[1][0]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if learn.data.valid_ds.__len__() == preds[1].shape[0]:\n",
    "    N = learn.data.valid_ds.__len__()\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "xs = [learn.data.valid_ds[i][0] for i in range(N)]\n",
    "ys = [learn.data.valid_ds[i][1] for i in range(N)]\n",
    "p0s = [Image(preds[0][i][0]) for i in range(N)]\n",
    "p1s = [Image(preds[0][i][1]) for i in range(N)]\n",
    "argmax = [Image(preds[0][i].argmax(dim=0)) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncol = 3\n",
    "nrow = N//ncol + 1\n",
    "fig=plt.figure(figsize=(12, nrow*5))\n",
    "for i in range(1,N):\n",
    "    fig.add_subplot(nrow, ncol, i)\n",
    "#     plt.imshow(xs[i-1].px.permute(1, 2, 0), cmap = \"Oranges\", alpha=0.5)\n",
    "    plt.imshow(argmax[i-1].px, cmap = \"Blues\", alpha=0.7)\n",
    "#     plt.imshow(p1s[i-1].px, cmap = \"Blues\", alpha=0.7)\n",
    "    plt.imshow(ys[i-1].px[0], cmap = \"Oranges\", alpha=0.5)\n",
    "# plt.savefig('/hpf/largeprojects/MICe/nwang/TissueVision/2019-05-31_Mallar_NeuralNet/figures/2019-06-12_mallar-results.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert arc-venus-train.ipynb --to html --output nbs/2019-08-21_RESNET34-hcolumns_arcvenus_clusters.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
